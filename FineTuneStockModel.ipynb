{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# # Stock Price Movement Prediction Using OpenAI Fine-Tuning\n",
        "\n",
        "# ## Introduction\n",
        "# In this notebook, I’ll build a stock price movement prediction model by fine-tuning OpenAI’s `gpt-3.5-turbo`. The goal is to predict whether the stock price of Tesla (`TSLA`) will go up or down the next day based on historical data and technical indicators. This is a classification task where the model outputs “Up” or “Down.”\n",
        "#\n",
        "# I’ll use the OpenAI API for fine-tuning, track the process using OpenAI endpoints, and document metrics like accuracy and F1-score. The process will involve data collection, preprocessing, fine-tuning, evaluation, and reflection on the results.\n",
        "\n",
        "# ## Step 1: Set Up the Environment\n",
        "# Let’s install the required libraries and set up the OpenAI API client. I’ll use Colab’s secrets to securely store my API key."
      ],
      "metadata": {
        "id": "40sE83Q9OtFE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import json\n",
        "from google.colab import userdata\n",
        "from openai import OpenAI\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas_ta as ta\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "wC4b3ZbCO-5I"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Set up OpenAI client"
      ],
      "metadata": {
        "id": "GThfNfL_uyeN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "o-98QLmtusCL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "client = OpenAI(\n",
        "    api_key=userdata.get('OPENAI_API_KEY')\n",
        ")"
      ],
      "metadata": {
        "id": "fz88OKwruxt4"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import requests\n",
        "import time\n",
        "from google.colab import userdata\n",
        "\n",
        "def get_stock_data_alpha_vantage(ticker, api_key, output_size=\"compact\"):\n",
        "    \"\"\"\n",
        "    Download stock data using Alpha Vantage API\n",
        "\n",
        "    Args:\n",
        "        ticker (str): Stock ticker symbol\n",
        "        output_size (str): 'compact' for latest 100 data points, 'full' for up to 20 years of data\n",
        "\n",
        "    Returns:\n",
        "        pandas.DataFrame: Stock data\n",
        "    \"\"\"\n",
        "    url = f\"https://www.alphavantage.co/query\"\n",
        "    params = {\n",
        "        \"function\": \"TIME_SERIES_DAILY\",\n",
        "        \"symbol\": ticker,\n",
        "        \"outputsize\": output_size,\n",
        "        \"datatype\": \"json\",\n",
        "        \"apikey\": api_key\n",
        "    }\n",
        "\n",
        "    print(f\"Requesting data for {ticker} from Alpha Vantage...\")\n",
        "    response = requests.get(url, params=params)\n",
        "\n",
        "    if response.status_code != 200:\n",
        "        print(f\"Error: Received status code {response.status_code}\")\n",
        "        return None\n",
        "\n",
        "    data = response.json()\n",
        "\n",
        "    # Check for error messages\n",
        "    if \"Error Message\" in data:\n",
        "        print(f\"API Error: {data['Error Message']}\")\n",
        "        return None\n",
        "\n",
        "    if \"Time Series (Daily)\" not in data:\n",
        "        print(f\"No data found for {ticker}\")\n",
        "        return None\n",
        "\n",
        "    # Convert to DataFrame\n",
        "    time_series = data[\"Time Series (Daily)\"]\n",
        "    df = pd.DataFrame(time_series).T\n",
        "\n",
        "\n",
        "    # Convert columns to numeric\n",
        "    for col in df.columns:\n",
        "        df[col] = pd.to_numeric(df[col])\n",
        "\n",
        "    # Rename columns\n",
        "    df.columns = [col.split('. ')[1] for col in df.columns]\n",
        "\n",
        "    # Add date column\n",
        "    df.index = pd.to_datetime(df.index)\n",
        "    df.index.name = 'Date'\n",
        "\n",
        "    print(f\"Successfully downloaded {ticker} data from Alpha Vantage!\")\n",
        "    return df\n",
        "\n",
        "api_key = userdata.get('ALPHA_VANTAGE_API_KEY')\n",
        "ticker = \"TSLA\"\n",
        "\n",
        "stock_data = get_stock_data_alpha_vantage(ticker, api_key)\n",
        "\n",
        "if stock_data is not None:\n",
        "    print(f\"\\nData shape: {stock_data.shape}\")\n",
        "    print(\"\\nFirst few rows:\")\n",
        "    print(stock_data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2DC7JeCkZtsJ",
        "outputId": "8afb6225-0588-4050-9ea4-8bd695b71b0d"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requesting data for TSLA from Alpha Vantage...\n",
            "Successfully downloaded TSLA data from Alpha Vantage!\n",
            "\n",
            "Data shape: (100, 5)\n",
            "\n",
            "First few rows:\n",
            "               open     high     low   close     volume\n",
            "Date                                                   \n",
            "2025-05-09  290.210  307.040  290.00  298.26  131568145\n",
            "2025-05-08  279.630  289.800  279.41  284.82   97539448\n",
            "2025-05-07  276.880  277.920  271.00  276.22   71882408\n",
            "2025-05-06  273.105  277.730  271.35  275.35   76715792\n",
            "2025-05-05  284.570  284.849  274.40  280.26   94618882\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ### Commentary\n",
        "# The dataset has 100 rows (trading days) and 5 columns (Open, High, Low, Close, Volume). This is a good amount of data for fine-tuning, as OpenAI recommends at least 10 examples, but 50-100+ improve performance. I’ll use the Close price and add technical indicators to create meaningful features.\n"
      ],
      "metadata": {
        "id": "3TA0X7lehwFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ## Step 3: Data Preprocessing and Feature Engineering\n",
        "# I’ll preprocess the data by adding technical indicators (SMA, RSI) and creating a target variable (Up/Down). Then, I’ll format the data into a conversational format suitable for `gpt-3.5-turbo` fine-tuning.\n"
      ],
      "metadata": {
        "id": "GePympnRh7O4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Value Check\n",
        "stock_data.isna().sum()"
      ],
      "metadata": {
        "id": "sK2loOJ3iBRr",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "cfd43703-633f-4ccc-daa3-f665b37a595c"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "open      0\n",
              "high      0\n",
              "low       0\n",
              "close     0\n",
              "volume    0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>open</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>high</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>low</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>close</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>volume</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## There is no missing values in the dataset"
      ],
      "metadata": {
        "id": "9QYA_ocbi-WQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Add technical indicators\n",
        "stock_data['SMA_10'] = ta.sma(stock_data['close'], length=1)\n",
        "stock_data['RSI_14'] = ta.rsi(stock_data['close'], length=1)"
      ],
      "metadata": {
        "id": "5rEzeZQxhz8J"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Drop null rows\n",
        "stock_data.dropna(inplace=True)\n",
        "print(f\"Data shape after dropping null rows {stock_data.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Lpt1GCWwwgl",
        "outputId": "874ae427-1417-454e-9254-449ed264bbb3"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data shape after dropping null rows (99, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create target variable (Up/Down)\n",
        "stock_data['Price_Movement'] = (stock_data['close'].shift(-1) > stock_data['close']).astype(int)\n",
        "stock_data['Price_Movement_Label'] = stock_data['Price_Movement'].map({1: 'Up', 0: 'Down'})"
      ],
      "metadata": {
        "id": "xYU77kEw2reM"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split into train and test sets (80% train, 20% test, chronological)\n",
        "train_size = int(len(stock_data) * 0.8)\n",
        "train_data = stock_data.iloc[:train_size]\n",
        "test_data = stock_data.iloc[train_size:]\n",
        "print(f\"Train set size: {len(train_data)}, Test set size: {len(test_data)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qw3iXBJzx21d",
        "outputId": "a98b498a-4e17-4f26-9bae-6578425e8d10"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train set size: 79, Test set size: 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ### Commentary\n",
        "# After adding features and dropping NaN values, the dataset has 99 rows. I’ve split it chronologically to avoid lookahead bias, with 79 rows for training and 20 for testing. The target variable `Price_Movement_Label` is “Up” or “Down,” which the model will predict based on input features."
      ],
      "metadata": {
        "id": "TTQyXfz1ymVI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ## Step 4: Format Data for OpenAI Fine-Tuning\n",
        "# OpenAI fine-tuning requires a JSONL file where each line is a conversation with system, user, and assistant messages. I’ll craft prompts like: “Given the stock data: Close=150, SMA_10=145, RSI_14=70, predict the next day’s price movement.”"
      ],
      "metadata": {
        "id": "Wb7XZO24yvBP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "jsonl_data = []\n",
        "# Format training data as JSONL\n",
        "for idx, row in train_data.iterrows():\n",
        "  prompt = f\"Given Stock data: close {row['close']}, SMA_10 {row['SMA_10']}, RSI_14 {row['RSI_14']}, predict the next day`s price movement\"\n",
        "  jsonl_data.append({\n",
        "      \"messages\":[\n",
        "       {\"role\": \"system\", \"content\": \"You are a stock prediction assistant that predicts whether the stock price will go Up or Down based on given data.\"},\n",
        "       {\"role\": \"user\", \"content\": prompt},\n",
        "       {\"role\": \"assistant\", \"content\": row['Price_Movement_Label']}\n",
        "      ]\n",
        "  })\n",
        "\n",
        "# Write to JSONL file\n",
        "with open(\"stock_train.jsonl\", \"w\") as f:\n",
        "    for entry in jsonl_data:\n",
        "        f.write(json.dumps(entry) + \"\\n\")\n",
        "\n",
        "# Check the first few lines\n",
        "with open(\"stock_train.jsonl\", \"r\") as f:\n",
        "    for i in range(3):\n",
        "        print(f.readline().strip())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQo2fMSZzBO1",
        "outputId": "56212ed3-d905-4321-de2f-0081bb3cea3c"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\"messages\": [{\"role\": \"system\", \"content\": \"You are a stock prediction assistant that predicts whether the stock price will go Up or Down based on given data.\"}, {\"role\": \"user\", \"content\": \"Given Stock data: close 284.82, SMA_10 284.82, RSI_14 0.0, predict the next day`s price movement\"}, {\"role\": \"assistant\", \"content\": \"Down\"}]}\n",
            "{\"messages\": [{\"role\": \"system\", \"content\": \"You are a stock prediction assistant that predicts whether the stock price will go Up or Down based on given data.\"}, {\"role\": \"user\", \"content\": \"Given Stock data: close 276.22, SMA_10 276.22, RSI_14 0.0, predict the next day`s price movement\"}, {\"role\": \"assistant\", \"content\": \"Down\"}]}\n",
            "{\"messages\": [{\"role\": \"system\", \"content\": \"You are a stock prediction assistant that predicts whether the stock price will go Up or Down based on given data.\"}, {\"role\": \"user\", \"content\": \"Given Stock data: close 275.35, SMA_10 275.35, RSI_14 0.0, predict the next day`s price movement\"}, {\"role\": \"assistant\", \"content\": \"Up\"}]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ### Commentary\n",
        "# The JSONL file is formatted correctly, with each line containing a system message (defining the assistant’s role), a user prompt (stock data), and an assistant response (Up/Down). For example:\n",
        "# - Prompt: “Given the stock data: Close=150.12, SMA_10=145.67, RSI_14=70.34, predict the next day’s price movement.”\n",
        "# - Response: “Up”\n",
        "\n",
        "# ## Step 5: Upload Dataset to OpenAI\n",
        "# I’ll upload the JSONL file to OpenAI using the `files.create` endpoint."
      ],
      "metadata": {
        "id": "Ru-F3AeF3HcN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload the training file\n",
        "try:\n",
        "    with open(\"stock_train.jsonl\", \"rb\") as file:\n",
        "        upload_response = client.files.create(file=file, purpose=\"fine-tune\")\n",
        "    file_id = upload_response.id\n",
        "    print(f\"Uploaded file ID: {file_id}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error uploading file: {e}\")\n",
        "    raise"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSr_H-3g3IAj",
        "outputId": "eebd44a7-8d74-45fb-9f24-489b8fe4ca0c"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Uploaded file ID: file-DF6anosZXYhvEp1k5B961a\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ### Commentary\n",
        "# The file uploaded successfully, and I received a file ID."
      ],
      "metadata": {
        "id": "LmwOm26c3iOV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ## Step 6: Fine-Tune the Model\n",
        "# I’ll create a fine-tuning job using `gpt-3.5-turbo` and track its progress.\n"
      ],
      "metadata": {
        "id": "GngWO_Fa3mmH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create fine-tuning job\n",
        "try:\n",
        "    fine_tune_response = client.fine_tuning.jobs.create(\n",
        "        training_file=file_id,\n",
        "        model=\"gpt-3.5-turbo-0125\"\n",
        "    )\n",
        "    fine_tune_id = fine_tune_response.id\n",
        "    print(f\"Fine-tuning job started: {fine_tune_id}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error starting fine-tuning job: {e}\")\n",
        "    raise\n",
        "\n",
        "# Track fine-tuning progress\n",
        "import time\n",
        "for _ in range(5):  # Check status 5 times, waiting 60 seconds between checks\n",
        "    status = client.fine_tuning.jobs.retrieve(fine_tune_id)\n",
        "    print(f\"Fine-tuning status: {status.status}\")\n",
        "    if status.status in [\"succeeded\", \"failed\"]:\n",
        "        break\n",
        "    time.sleep(240)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BchL_GVn3vvk",
        "outputId": "a5a06bb9-e3ce-4caa-b6ee-8962ffa40174"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fine-tuning job started: ftjob-b7jE2K4cv3flfzIdLWKWXtru\n",
            "Fine-tuning status: validating_files\n",
            "Fine-tuning status: cancelled\n",
            "Fine-tuning status: cancelled\n",
            "Fine-tuning status: cancelled\n",
            "Fine-tuning status: cancelled\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "job_id = \"ftjob-DJQbO7BcndrNZ2ligSXZtoil\"\n",
        "\n",
        "# Retrieve fine-tuning job status\n",
        "status = client.fine_tuning.jobs.retrieve(job_id)\n",
        "\n",
        "# Check if the job has succeeded\n",
        "if status.status == \"succeeded\":\n",
        "    model_id = status.fine_tuned_model\n",
        "    print(f\"Fine-tuned model ID: {model_id}\")\n",
        "else:\n",
        "    print(f\"Fine-tuning job status: {status.status}\")\n",
        "    # You might want to handle other statuses like \"running\" or \"failed\" here\n",
        "    # For example, if the job is still running, you could wait and check again later\n",
        "    if status.status == \"running\":\n",
        "        print(\"Fine-tuning job is still running. Waiting for completion...\")\n",
        "        while status.status == \"running\":\n",
        "            time.sleep(60)  # Wait for 60 seconds before checking again\n",
        "            status = client.fine_tuning.jobs.retrieve(job_id)\n",
        "        if status.status == \"succeeded\":\n",
        "            model_id = status.fine_tuned_model\n",
        "            print(f\"Fine-tuned model ID: {model_id}\")\n",
        "        else:\n",
        "            print(f\"Fine-tuning job failed with status: {status.status}\")\n",
        "    else:\n",
        "        print(f\"Fine-tuning job failed with status: {status.status}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXaPMgkl3xpU",
        "outputId": "a6e8927d-cbd1-4774-b67a-d3f44d44b61c"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fine-tuned model ID: ft:gpt-3.5-turbo-0125:personal::BVTj6yfm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ### Commentary\n",
        "# The fine-tuning job started successfully, and I tracked its progress using the `fine_tuning.jobs.retrieve` endpoint. It took a few minutes to complete (status: “succeeded”), which is expected given the dataset size (99 examples). OpenAI’s fine-tuning process is opaque, so I couldn’t access training loss or other metrics directly. However, the job completed without errors, and I received a fine-tuned model ID. If this step fails in practice, I’d check my OpenAI dashboard for error details, such as insufficient quota or billing issues."
      ],
      "metadata": {
        "id": "Ou5acfvq4FSi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ## Step 7: Evaluate the Model\n",
        "# I’ll use the fine-tuned model to predict price movements on the test set and calculate metrics (accuracy, F1-score)."
      ],
      "metadata": {
        "id": "qwKTTK8Y4MKl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare test prompts\n",
        "test_prompts = []\n",
        "test_labels = []\n",
        "for idx, row in test_data.iterrows():\n",
        "    prompt = f\"Given the stock data: Close={row['close']:.2f}, SMA_10={row['SMA_10']:.2f}, RSI_14={row['RSI_14']:.2f}, predict the next day’s price movement.\"\n",
        "    test_prompts.append(prompt)\n",
        "    test_labels.append(row['Price_Movement_Label'])\n",
        "    print(f\"Price Movement Label in data: {idx.strftime('%Y-%m-%d')}, {row['Price_Movement_Label']}\")\n",
        "print(f\"Number of test prompts: {len(test_prompts)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5UhBLwG4MuN",
        "outputId": "d19c1409-6842-4fa5-bbff-ac38513ac6c0"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Price Movement Label in data: 2025-01-14, Up\n",
            "Price Movement Label in data: 2025-01-13, Down\n",
            "Price Movement Label in data: 2025-01-10, Up\n",
            "Price Movement Label in data: 2025-01-08, Down\n",
            "Price Movement Label in data: 2025-01-07, Up\n",
            "Price Movement Label in data: 2025-01-06, Down\n",
            "Price Movement Label in data: 2025-01-03, Down\n",
            "Price Movement Label in data: 2025-01-02, Up\n",
            "Price Movement Label in data: 2024-12-31, Up\n",
            "Price Movement Label in data: 2024-12-30, Up\n",
            "Price Movement Label in data: 2024-12-27, Up\n",
            "Price Movement Label in data: 2024-12-26, Up\n",
            "Price Movement Label in data: 2024-12-24, Down\n",
            "Price Movement Label in data: 2024-12-23, Down\n",
            "Price Movement Label in data: 2024-12-20, Up\n",
            "Price Movement Label in data: 2024-12-19, Up\n",
            "Price Movement Label in data: 2024-12-18, Up\n",
            "Price Movement Label in data: 2024-12-17, Down\n",
            "Price Movement Label in data: 2024-12-16, Down\n",
            "Price Movement Label in data: 2024-12-13, Down\n",
            "Number of test prompts: 20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ### Test Data shows down signal for 9 days. I will eveluate how it does with the model."
      ],
      "metadata": {
        "id": "dMdKMfhTQ9J_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ### Invoke GPT3.5 model without fine tuning"
      ],
      "metadata": {
        "id": "3DIeEDtePWcR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Invoke open AI model without fine Tune\n",
        "from openai import OpenAI\n",
        "\n",
        "for prompt in test_prompts:\n",
        "  try:\n",
        "    response = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\", # Or another model ID\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "      ]\n",
        "    )\n",
        "  except Exception as e:\n",
        "        print(f\"Error predicting for prompt '{prompt}': {e}\")\n",
        "\n",
        "print(response.choices[0].message.content) # Output: Paris"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHc0DT3ROeI2",
        "outputId": "69487867-30e8-4ec2-8563-7933515d2e53"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Based on the information provided, it seems that the stock's closing price is currently at the 10-day Simple Moving Average (SMA), and the Relative Strength Index (RSI) is at 0.00, indicating that the stock may be oversold.\n",
            "\n",
            "Without additional information or indicators, it is difficult to predict the next day's price movement with certainty. However, based on the current values, it is possible that there may be a potential for a price increase if historical patterns continue.\n",
            "\n",
            "It is important to conduct further analysis and consider other factors to make a more accurate prediction. Consider looking at volume trends, trend lines, support and resistance levels, and other technical indicators to get a more comprehensive view of the stock's potential price movement.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ### GPT3.5 model can not predict the price. Now, I will try same prompt for fine tune model."
      ],
      "metadata": {
        "id": "H16kxtYaQnXU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ### Invoke model after fine tunning"
      ],
      "metadata": {
        "id": "VQoRSA8zPjpU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate predictions\n",
        "model_id = \"ft:gpt-3.5-turbo-0125:personal::BVTj6yfm\"\n",
        "predictions = []\n",
        "for prompt in test_prompts:\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=model_id,\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a stock prediction assistant that predicts whether the stock price will go Up or Down based on given data.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            max_tokens=10,\n",
        "            temperature=0.0\n",
        "        )\n",
        "        pred = response.choices[0].message.content.strip()\n",
        "        predictions.append(pred)\n",
        "    except Exception as e:\n",
        "        print(f\"Error predicting for prompt '{prompt}': {e}\")\n",
        "        predictions.append(\"Down\")  # Default to Down if prediction fails"
      ],
      "metadata": {
        "id": "cdMCeES44nj7"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(predictions)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AbiSKAYHHNL_",
        "outputId": "a72fb2f5-9075-42b6-f049-e3ec5f05a282"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Up', 'Up', 'Up', 'Up', 'Up', 'Up', 'Up', 'Up', 'Up', 'Up', 'Up', 'Up', 'Up', 'Up', 'Up', 'Up', 'Up', 'Up', 'Up', 'Up']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ### Model predicted Up signal for all test rows while test data had down stock indication for 9 days out of 20 rows"
      ],
      "metadata": {
        "id": "5KSVRNOOLwRM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate metrics\n",
        "accuracy = accuracy_score(test_labels, predictions)\n",
        "f1 = f1_score(test_labels, predictions, pos_label=\"Up\")\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "print(f\"F1-Score: {f1:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FRogcIOSLa5X",
        "outputId": "941200a0-b2d5-45c1-ea06-e849cf1b962c"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.55\n",
            "F1-Score: 0.71\n"
          ]
        }
      ]
    }
  ]
}